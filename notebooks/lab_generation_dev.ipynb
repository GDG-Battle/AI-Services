{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b2537a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "def pptx_parser(file_path):\n",
    "    \"\"\"\n",
    "    Parses a PowerPoint file and returns its content as a list of documents.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the PowerPoint file.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of documents extracted from the PowerPoint file.\n",
    "    \"\"\"\n",
    "    loader = UnstructuredPowerPointLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8eb7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "available_extentions = ['pptx', 'ppt']\n",
    "\n",
    "def parse_file(file_path, extentions=available_extentions):\n",
    "    \"\"\"\n",
    "    Parses a file based on its extension and returns its content.\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    # get the file's extension\n",
    "    file_extension = file_path.split('.')[-1].lower()\n",
    "    if file_extension not in extentions:\n",
    "        raise ValueError(f\"Unsupported file extension: {file_extension}\")\n",
    "    if file_extension in ['pptx', 'ppt']:\n",
    "        return pptx_parser(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file extension: {file_extension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b44560",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File not found: ../data/Introduction to generative AI.pptx",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m file_path = \u001b[33m\"\u001b[39m\u001b[33m../data/Introduction to generative AI.pptx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m documents = \u001b[43mparse_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(doc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mparse_file\u001b[39m\u001b[34m(file_path, extentions)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Check if file exists\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(file_path):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# get the file's extension\u001b[39;00m\n\u001b[32m     12\u001b[39m file_extension = file_path.split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)[-\u001b[32m1\u001b[39m].lower()\n",
      "\u001b[31mFileNotFoundError\u001b[39m: File not found: ../data/Introduction to generative AI.pptx"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/documents/Introduction to generative AI.pptx\"\n",
    "documents = parse_file(file_path)\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf38a48",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m text_splitter.split_documents(documents)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Chunk the documents\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m chunked_documents = chunk_documents(\u001b[43mdocuments\u001b[49m)\n\u001b[32m     24\u001b[39m chunked_documents\n",
      "\u001b[31mNameError\u001b[39m: name 'documents' is not defined"
     ]
    }
   ],
   "source": [
    "# chunking the documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "def chunk_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Splits documents into smaller chunks.\n",
    "\n",
    "    Args:\n",
    "        documents (list): List of documents to be chunked.\n",
    "        chunk_size (int): Size of each chunk.\n",
    "        chunk_overlap (int): Overlap between chunks.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of text chunks.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "# Chunk the documents\n",
    "chunked_documents = chunk_documents(documents)\n",
    "chunked_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c57c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing the documents using QDrant\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "import os, dotenv\n",
    "from datetime import datetime\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n",
    "EMBEDDING_MODEL_NAME = \"nv-embed-v1\"\n",
    "\n",
    "def index_documents(documents, collection_name=\"pptx_collection\"+str(int(datetime.now().timestamp())), qdrant_url=QDRANT_URL, embedding_model_name=EMBEDDING_MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Indexes documents using QDrant vector store.\n",
    "\n",
    "    Args:\n",
    "        documents (list): List of documents to be indexed.\n",
    "        collection_name (str): Name of the QDrant collection.\n",
    "        qdrant_url (str): URL of the QDrant instance.\n",
    "        embedding_model_name (str): Name of the embedding model to use.\n",
    "\n",
    "    Returns:\n",
    "        Qdrant: The indexed QDrant vector store.\n",
    "    \"\"\"\n",
    "    vectorstore = QdrantVectorStore.from_documents(\n",
    "        documents,\n",
    "        embedding=NVIDIAEmbeddings(model_name=embedding_model_name, nvidia_api_key=os.getenv(\"NVIDIA_API_KEY\")),\n",
    "        collection_name=collection_name,\n",
    "        url=qdrant_url,\n",
    "        prefer_grpc=True,\n",
    "    )\n",
    "    return vectorstore\n",
    "\n",
    "# get vectorstore\n",
    "def get_vectorstore(collection_name=\"pptx_collection\", qdrant_url=QDRANT_URL, embedding_model_name=EMBEDDING_MODEL_NAME):\n",
    "    \"\"\"\n",
    "    get vectorstore with specified collection name and QDrant URL.\n",
    "\n",
    "    Returns:\n",
    "        Qdrant: The QDrant vector store.\n",
    "    \"\"\"\n",
    "    return QdrantVectorStore.from_existing_collection(\n",
    "        collection_name=collection_name,\n",
    "        url=qdrant_url,\n",
    "        embedding=NVIDIAEmbeddings(model_name=embedding_model_name),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e508049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benhima/pi/ai-services/.venv/lib/python3.12/site-packages/langchain_qdrant/qdrant.py:808: UserWarning: Qdrant client version 1.14.2 is incompatible with server version 1.10.1. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
      "  client = QdrantClient(**client_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 10 documents into QDrant collection 'genai'.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "vectorstore = index_documents(chunked_documents, collection_name=\"genai\")\n",
    "print(f\"Indexed {len(chunked_documents)} documents into QDrant collection '{vectorstore.collection_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d9a6e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benhima/pi/ai-services/.venv/lib/python3.12/site-packages/langchain_qdrant/qdrant.py:397: UserWarning: Qdrant client version 1.14.2 is incompatible with server version 1.10.1. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
      "  client = QdrantClient(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved vectorstore with collection name: genai\n"
     ]
    }
   ],
   "source": [
    "# get the vectorstore\n",
    "vectorstore = get_vectorstore(collection_name=\"genai\")\n",
    "print(f\"Retrieved vectorstore with collection name: {vectorstore.collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ca1b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Multi-Agent Lab Generation Workflow\n",
    "#\n",
    "# Roles:\n",
    "#  - planner_agent: decide QCM vs coding exercise and difficulty level\n",
    "#  - retriever_agent: split documents, embed chunks, retrieve relevant ones\n",
    "#  - qcm_generator_agent: generate MCQ questions/options/correct_answer\n",
    "#  - code_generator_agent: produce coding exercise description and stub\n",
    "#  - test_generator_agent: create unit tests: input/output pairs\n",
    "#  - executor_agent: run the code against tests and capture results\n",
    "#  - evaluator_agent: check test outcomes; if failure, trigger refinement loop\n",
    "#\n",
    "# Workflow:\n",
    "#  1. load_documents(paths: List[str]) -> raw_texts\n",
    "#  2. chunk_texts(raw_texts) -> chunks\n",
    "#  3. embed_and_store(chunks) in vector DB\n",
    "#  4. planner = planner_agent(user_query, metadata)\n",
    "#     if planner.task == \"qcm\":\n",
    "#         chunks = retriever_agent(planner.topic)\n",
    "#         qcms = qcm_generator_agent(chunks, planner.difficulty)\n",
    "#         evaluator_agent.validate_qcm(qcms)\n",
    "#     elif planner.task == \"code\":\n",
    "#         chunks = retriever_agent(planner.topic)\n",
    "#         stub = code_generator_agent(chunks, planner.difficulty)\n",
    "#         tests = test_generator_agent(stub, chunks)\n",
    "#         result = executor_agent.run_tests(stub, tests)\n",
    "#         evaluator_agent.loop_until_pass(stub, tests, result)\n",
    "#\n",
    "# Each agent should be implemented as a separate function or class method.\n",
    "# Use LangChain + LangGraph for orchestration; vector DB for chunk retrieval;\n",
    "# code sandbox for execution.\n",
    "#\n",
    "# Convention:\n",
    "#  - Clear function signatures for each agent\n",
    "#  - Use meaningful names and type hints\n",
    "#  - Keep each agent focused on its responsibility\n",
    "#\n",
    "# Goals:\n",
    "#  - Modular, testable, and easy-to-debug pipeline\n",
    "#  - Support iterative refinement via evaluator loops\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d496fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from typing import Dict\n",
    "from langchain_qdrant import Qdrant\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "MODEL_NAME = \"meta/llama-3.3-70b-instruct\"\n",
    "\n",
    "# --- QCM generator using ReAct agent ---\n",
    "def qcm_pipeline(user_query: str, vectorstore: Qdrant, difficulty: str, context: str, number_of_questions: int) -> Dict:\n",
    "    llm = ChatNVIDIA(model=MODEL_NAME, nvidia_api_key=os.getenv(\"NVIDIA_API_KEY\"))\n",
    "\n",
    "\n",
    "    # Pre-fetch context (5 docs max)\n",
    "    docs = vectorstore.similarity_search(user_query, k=5)\n",
    "    context_text = \"\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    # Prepare prompt with explicit context\n",
    "    sys_msg = SystemMessage(content=(\n",
    "        f\"You are an educational assistant. Using the context below, generate exactly {number_of_questions} multiple-choice questions at the '{difficulty}' level. \"\n",
    "        f\"Each question must have exactly 3 plausible options and ONLY ONE correct answer.\\n\\n\"\n",
    "        f\"Context:\\n{context_text}\\n{context}\\n\\n\"\n",
    "        \"Return only a valid JSON in this exact format (use double quotes for all keys and string values):\\n\"\n",
    "        '''{\n",
    "    \"quiz\": [\n",
    "        {\n",
    "        \"question\": \"string\",\n",
    "        \"options\": [\"option1\", \"option2\", \"option3\"],\n",
    "        \"answer\": 1\n",
    "        }\n",
    "        // Repeat this format for each question\n",
    "    ]\n",
    "    }'''\n",
    "        f\"\\nYou MUST return exactly {number_of_questions} questions inside the 'quiz' array. No more, no less. Do NOT explain. Only output the JSON.\"\n",
    "    ))\n",
    "\n",
    "\n",
    "    human_msg = HumanMessage(content=f\"Generate a question about: {user_query}\")\n",
    "\n",
    "    # No retrieval tool needed here, just pass the LLM\n",
    "    agent = create_react_agent(model=llm, tools=[], debug=True)\n",
    "\n",
    "    result = agent.invoke({\"messages\": [sys_msg, human_msg]})\n",
    "\n",
    "    try:\n",
    "        parsed = json.loads(result['messages'][-1].content.strip().strip(\"```json\").strip(\"```\"))\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"Output is not valid JSON:\\n{result['messages'][-1].content}\")\n",
    "\n",
    "    return parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "890af72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [SystemMessage(content='You are an educational assistant. Using the context below, generate exactly 10 multiple-choice questions at the \\'medium\\' level. Each question must have exactly 3 plausible options and ONLY ONE correct answer.\\n\\nContext:\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\n\\nTransformer-\\x0bbased models published: PaLM, PaLM2, Imagen, Parti, Phenaki\\n\\n2022\\n\\nStable diffusion announced, downloadable\\n\\n2023\\n\\nGoogle Research and \\x0bGoogle DeepMind solidify \\x0blarge model efforts in Gemini \\x0bprogram for a world class \\x0bmultimodal model (Dec)\\n\\n2022\\n\\nGoogle AI Test \\x0bKitchen announces guardrailed LaMDA\\n\\n2017\\n\\nGoogle publishes Transformer paper\\n\\n2018\\n\\nGoogle AI Principles published\\n\\n2022\\n\\nChatGPT \\x0bannounced, available \\x0bto public (Nov)\\n\\n2023\\n\\nBard\\x0bAnnounced \\x0b(Feb)\\n\\n2023\\n\\nDeveloper access, \\x0bCloud access via \\x0bAPI at I/O 2023\\n\\nLarge, pre-Transformer models (e.g., MUM) applied to many products \\x0b(e.g., Google Search, Translate, Maps)\\n\\n\\n\\nTwo important choices\\n\\nProprietary + Confidential\\n\\nWhat Model?\\n\\nWhat Infrastructure?\\n\\n洟能\n\\n\\n\\nFinding the right open model\\n\\n\\nReturn only a valid JSON in this exact format (use double quotes for all keys and string values):\\n{\\n    \"quiz\": [\\n        {\\n        \"question\": \"string\",\\n        \"options\": [\"option1\", \"option2\", \"option3\"],\\n        \"answer\": 1\\n        }\\n        // Repeat this format for each question\\n    ]\\n    }\\nYou MUST return exactly 10 questions inside the \\'quiz\\' array. No more, no less. Do NOT explain. Only output the JSON.', additional_kwargs={}, response_metadata={}),\n",
      "              HumanMessage(content='Generate a question about: generative AI', additional_kwargs={}, response_metadata={})]}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [SystemMessage(content='You are an educational assistant. Using the context below, generate exactly 10 multiple-choice questions at the \\'medium\\' level. Each question must have exactly 3 plausible options and ONLY ONE correct answer.\\n\\nContext:\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\n\\nTransformer-\\x0bbased models published: PaLM, PaLM2, Imagen, Parti, Phenaki\\n\\n2022\\n\\nStable diffusion announced, downloadable\\n\\n2023\\n\\nGoogle Research and \\x0bGoogle DeepMind solidify \\x0blarge model efforts in Gemini \\x0bprogram for a world class \\x0bmultimodal model (Dec)\\n\\n2022\\n\\nGoogle AI Test \\x0bKitchen announces guardrailed LaMDA\\n\\n2017\\n\\nGoogle publishes Transformer paper\\n\\n2018\\n\\nGoogle AI Principles published\\n\\n2022\\n\\nChatGPT \\x0bannounced, available \\x0bto public (Nov)\\n\\n2023\\n\\nBard\\x0bAnnounced \\x0b(Feb)\\n\\n2023\\n\\nDeveloper access, \\x0bCloud access via \\x0bAPI at I/O 2023\\n\\nLarge, pre-Transformer models (e.g., MUM) applied to many products \\x0b(e.g., Google Search, Translate, Maps)\\n\\n\\n\\nTwo important choices\\n\\nProprietary + Confidential\\n\\nWhat Model?\\n\\nWhat Infrastructure?\\n\\n洟能\n\\n\\n\\nFinding the right open model\\n\\n\\nReturn only a valid JSON in this exact format (use double quotes for all keys and string values):\\n{\\n    \"quiz\": [\\n        {\\n        \"question\": \"string\",\\n        \"options\": [\"option1\", \"option2\", \"option3\"],\\n        \"answer\": 1\\n        }\\n        // Repeat this format for each question\\n    ]\\n    }\\nYou MUST return exactly 10 questions inside the \\'quiz\\' array. No more, no less. Do NOT explain. Only output the JSON.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='Generate a question about: generative AI', additional_kwargs={}, response_metadata={})]\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [SystemMessage(content='You are an educational assistant. Using the context below, generate exactly 10 multiple-choice questions at the \\'medium\\' level. Each question must have exactly 3 plausible options and ONLY ONE correct answer.\\n\\nContext:\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\n\\nTransformer-\\x0bbased models published: PaLM, PaLM2, Imagen, Parti, Phenaki\\n\\n2022\\n\\nStable diffusion announced, downloadable\\n\\n2023\\n\\nGoogle Research and \\x0bGoogle DeepMind solidify \\x0blarge model efforts in Gemini \\x0bprogram for a world class \\x0bmultimodal model (Dec)\\n\\n2022\\n\\nGoogle AI Test \\x0bKitchen announces guardrailed LaMDA\\n\\n2017\\n\\nGoogle publishes Transformer paper\\n\\n2018\\n\\nGoogle AI Principles published\\n\\n2022\\n\\nChatGPT \\x0bannounced, available \\x0bto public (Nov)\\n\\n2023\\n\\nBard\\x0bAnnounced \\x0b(Feb)\\n\\n2023\\n\\nDeveloper access, \\x0bCloud access via \\x0bAPI at I/O 2023\\n\\nLarge, pre-Transformer models (e.g., MUM) applied to many products \\x0b(e.g., Google Search, Translate, Maps)\\n\\n\\n\\nTwo important choices\\n\\nProprietary + Confidential\\n\\nWhat Model?\\n\\nWhat Infrastructure?\\n\\n洟能\n\\n\\n\\nFinding the right open model\\n\\n\\nReturn only a valid JSON in this exact format (use double quotes for all keys and string values):\\n{\\n    \"quiz\": [\\n        {\\n        \"question\": \"string\",\\n        \"options\": [\"option1\", \"option2\", \"option3\"],\\n        \"answer\": 1\\n        }\\n        // Repeat this format for each question\\n    ]\\n    }\\nYou MUST return exactly 10 questions inside the \\'quiz\\' array. No more, no less. Do NOT explain. Only output the JSON.', additional_kwargs={}, response_metadata={}, id='9c86dffe-a479-43ac-9467-1d1ff71cea65'),\n",
      "              HumanMessage(content='Generate a question about: generative AI', additional_kwargs={}, response_metadata={}, id='ff7f55e7-1a22-4038-933d-5ab2e3b55c20')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'is_last_step': False,\n",
      " 'messages': [SystemMessage(content='You are an educational assistant. Using the context below, generate exactly 10 multiple-choice questions at the \\'medium\\' level. Each question must have exactly 3 plausible options and ONLY ONE correct answer.\\n\\nContext:\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\n\\nTransformer-\\x0bbased models published: PaLM, PaLM2, Imagen, Parti, Phenaki\\n\\n2022\\n\\nStable diffusion announced, downloadable\\n\\n2023\\n\\nGoogle Research and \\x0bGoogle DeepMind solidify \\x0blarge model efforts in Gemini \\x0bprogram for a world class \\x0bmultimodal model (Dec)\\n\\n2022\\n\\nGoogle AI Test \\x0bKitchen announces guardrailed LaMDA\\n\\n2017\\n\\nGoogle publishes Transformer paper\\n\\n2018\\n\\nGoogle AI Principles published\\n\\n2022\\n\\nChatGPT \\x0bannounced, available \\x0bto public (Nov)\\n\\n2023\\n\\nBard\\x0bAnnounced \\x0b(Feb)\\n\\n2023\\n\\nDeveloper access, \\x0bCloud access via \\x0bAPI at I/O 2023\\n\\nLarge, pre-Transformer models (e.g., MUM) applied to many products \\x0b(e.g., Google Search, Translate, Maps)\\n\\n\\n\\nTwo important choices\\n\\nProprietary + Confidential\\n\\nWhat Model?\\n\\nWhat Infrastructure?\\n\\n洟能\n\\n\\n\\nFinding the right open model\\n\\n\\nReturn only a valid JSON in this exact format (use double quotes for all keys and string values):\\n{\\n    \"quiz\": [\\n        {\\n        \"question\": \"string\",\\n        \"options\": [\"option1\", \"option2\", \"option3\"],\\n        \"answer\": 1\\n        }\\n        // Repeat this format for each question\\n    ]\\n    }\\nYou MUST return exactly 10 questions inside the \\'quiz\\' array. No more, no less. Do NOT explain. Only output the JSON.', additional_kwargs={}, response_metadata={}, id='9c86dffe-a479-43ac-9467-1d1ff71cea65'),\n",
      "              HumanMessage(content='Generate a question about: generative AI', additional_kwargs={}, response_metadata={}, id='ff7f55e7-1a22-4038-933d-5ab2e3b55c20')],\n",
      " 'remaining_steps': 24}\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='{\\n    \"quiz\": [\\n        {\\n            \"question\": \"What type of AI is capable of generating text, images, and code?\",\\n            \"options\": [\"Predictive AI\", \"Generative AI\", \"Multimodal AI\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"Which of the following is a characteristic of Generative AI?\",\\n            \"options\": [\"Limited to regression and classification tasks\", \"Able to understand and interpret human language\", \"Only capable of image recognition\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"What is the primary function of a Large Language Model (LLM)?\",\\n            \"options\": [\"To recognize and interpret human language\", \"To generate images and videos\", \"To perform mathematical calculations\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"What is an example of a Generative AI application?\",\\n            \"options\": [\"Sentiment analysis\", \"Text generation\", \"Object detection\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"What type of data is used to train Large Language Models?\",\\n            \"options\": [\"Image data\", \"Text data\", \"Audio data\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"Which of the following is a benefit of using Generative AI?\",\\n            \"options\": [\"Improved accuracy in predictive modeling\", \"Increased efficiency in data analysis\", \"Enhanced creativity in content generation\"],\\n            \"answer\": 2\\n        },\\n        {\\n            \"question\": \"What is the name of the Google chatbot that was published in 2021?\",\\n            \"options\": [\"LaMDA\", \"PaLM\", \"Bard\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"Which company announced the development of a large multimodal model called Gemini in 2022?\",\\n            \"options\": [\"Google\", \"Microsoft\", \"Amazon\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"What is the name of the Google program that aims to develop a world-class multimodal model?\",\\n            \"options\": [\"Gemini\", \"PaLM\", \"Vertex AI\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"In what year did Google start working on ML Fairness?\",\\n            \"options\": [\"2014\", \"2017\", \"2021\"],\\n            \"answer\": 0\\n        }\\n    ]\\n}', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': '{\\n    \"quiz\": [\\n        {\\n            \"question\": \"What type of AI is capable of generating text, images, and code?\",\\n            \"options\": [\"Predictive AI\", \"Generative AI\", \"Multimodal AI\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"Which of the following is a characteristic of Generative AI?\",\\n            \"options\": [\"Limited to regression and classification tasks\", \"Able to understand and interpret human language\", \"Only capable of image recognition\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"What is the primary function of a Large Language Model (LLM)?\",\\n            \"options\": [\"To recognize and interpret human language\", \"To generate images and videos\", \"To perform mathematical calculations\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"What is an example of a Generative AI application?\",\\n            \"options\": [\"Sentiment analysis\", \"Text generation\", \"Object detection\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"What type of data is used to train Large Language Models?\",\\n            \"options\": [\"Image data\", \"Text data\", \"Audio data\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"Which of the following is a benefit of using Generative AI?\",\\n            \"options\": [\"Improved accuracy in predictive modeling\", \"Increased efficiency in data analysis\", \"Enhanced creativity in content generation\"],\\n            \"answer\": 2\\n        },\\n        {\\n            \"question\": \"What is the name of the Google chatbot that was published in 2021?\",\\n            \"options\": [\"LaMDA\", \"PaLM\", \"Bard\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"Which company announced the development of a large multimodal model called Gemini in 2022?\",\\n            \"options\": [\"Google\", \"Microsoft\", \"Amazon\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"What is the name of the Google program that aims to develop a world-class multimodal model?\",\\n            \"options\": [\"Gemini\", \"PaLM\", \"Vertex AI\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"In what year did Google start working on ML Fairness?\",\\n            \"options\": [\"2014\", \"2017\", \"2021\"],\\n            \"answer\": 0\\n        }\\n    ]\\n}', 'token_usage': {'prompt_tokens': 1282, 'total_tokens': 1790, 'completion_tokens': 508}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.3-70b-instruct'}, id='run--6e602a09-b205-4d25-8613-9b47c6a5b04c-0', usage_metadata={'input_tokens': 1282, 'output_tokens': 508, 'total_tokens': 1790}, role='assistant')]\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'messages': [SystemMessage(content='You are an educational assistant. Using the context below, generate exactly 10 multiple-choice questions at the \\'medium\\' level. Each question must have exactly 3 plausible options and ONLY ONE correct answer.\\n\\nContext:\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\n\\nTransformer-\\x0bbased models published: PaLM, PaLM2, Imagen, Parti, Phenaki\\n\\n2022\\n\\nStable diffusion announced, downloadable\\n\\n2023\\n\\nGoogle Research and \\x0bGoogle DeepMind solidify \\x0blarge model efforts in Gemini \\x0bprogram for a world class \\x0bmultimodal model (Dec)\\n\\n2022\\n\\nGoogle AI Test \\x0bKitchen announces guardrailed LaMDA\\n\\n2017\\n\\nGoogle publishes Transformer paper\\n\\n2018\\n\\nGoogle AI Principles published\\n\\n2022\\n\\nChatGPT \\x0bannounced, available \\x0bto public (Nov)\\n\\n2023\\n\\nBard\\x0bAnnounced \\x0b(Feb)\\n\\n2023\\n\\nDeveloper access, \\x0bCloud access via \\x0bAPI at I/O 2023\\n\\nLarge, pre-Transformer models (e.g., MUM) applied to many products \\x0b(e.g., Google Search, Translate, Maps)\\n\\n\\n\\nTwo important choices\\n\\nProprietary + Confidential\\n\\nWhat Model?\\n\\nWhat Infrastructure?\\n\\n洟能\n\\n\\n\\nFinding the right open model\\n\\n\\nReturn only a valid JSON in this exact format (use double quotes for all keys and string values):\\n{\\n    \"quiz\": [\\n        {\\n        \"question\": \"string\",\\n        \"options\": [\"option1\", \"option2\", \"option3\"],\\n        \"answer\": 1\\n        }\\n        // Repeat this format for each question\\n    ]\\n    }\\nYou MUST return exactly 10 questions inside the \\'quiz\\' array. No more, no less. Do NOT explain. Only output the JSON.', additional_kwargs={}, response_metadata={}, id='9c86dffe-a479-43ac-9467-1d1ff71cea65'),\n",
      "              HumanMessage(content='Generate a question about: generative AI', additional_kwargs={}, response_metadata={}, id='ff7f55e7-1a22-4038-933d-5ab2e3b55c20'),\n",
      "              AIMessage(content='{\\n    \"quiz\": [\\n        {\\n            \"question\": \"What type of AI is capable of generating text, images, and code?\",\\n            \"options\": [\"Predictive AI\", \"Generative AI\", \"Multimodal AI\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"Which of the following is a characteristic of Generative AI?\",\\n            \"options\": [\"Limited to regression and classification tasks\", \"Able to understand and interpret human language\", \"Only capable of image recognition\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"What is the primary function of a Large Language Model (LLM)?\",\\n            \"options\": [\"To recognize and interpret human language\", \"To generate images and videos\", \"To perform mathematical calculations\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"What is an example of a Generative AI application?\",\\n            \"options\": [\"Sentiment analysis\", \"Text generation\", \"Object detection\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"What type of data is used to train Large Language Models?\",\\n            \"options\": [\"Image data\", \"Text data\", \"Audio data\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"Which of the following is a benefit of using Generative AI?\",\\n            \"options\": [\"Improved accuracy in predictive modeling\", \"Increased efficiency in data analysis\", \"Enhanced creativity in content generation\"],\\n            \"answer\": 2\\n        },\\n        {\\n            \"question\": \"What is the name of the Google chatbot that was published in 2021?\",\\n            \"options\": [\"LaMDA\", \"PaLM\", \"Bard\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"Which company announced the development of a large multimodal model called Gemini in 2022?\",\\n            \"options\": [\"Google\", \"Microsoft\", \"Amazon\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"What is the name of the Google program that aims to develop a world-class multimodal model?\",\\n            \"options\": [\"Gemini\", \"PaLM\", \"Vertex AI\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"In what year did Google start working on ML Fairness?\",\\n            \"options\": [\"2014\", \"2017\", \"2021\"],\\n            \"answer\": 0\\n        }\\n    ]\\n}', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': '{\\n    \"quiz\": [\\n        {\\n            \"question\": \"What type of AI is capable of generating text, images, and code?\",\\n            \"options\": [\"Predictive AI\", \"Generative AI\", \"Multimodal AI\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"Which of the following is a characteristic of Generative AI?\",\\n            \"options\": [\"Limited to regression and classification tasks\", \"Able to understand and interpret human language\", \"Only capable of image recognition\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"What is the primary function of a Large Language Model (LLM)?\",\\n            \"options\": [\"To recognize and interpret human language\", \"To generate images and videos\", \"To perform mathematical calculations\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"What is an example of a Generative AI application?\",\\n            \"options\": [\"Sentiment analysis\", \"Text generation\", \"Object detection\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"What type of data is used to train Large Language Models?\",\\n            \"options\": [\"Image data\", \"Text data\", \"Audio data\"],\\n            \"answer\": 1\\n        },\\n        {\\n            \"question\": \"Which of the following is a benefit of using Generative AI?\",\\n            \"options\": [\"Improved accuracy in predictive modeling\", \"Increased efficiency in data analysis\", \"Enhanced creativity in content generation\"],\\n            \"answer\": 2\\n        },\\n        {\\n            \"question\": \"What is the name of the Google chatbot that was published in 2021?\",\\n            \"options\": [\"LaMDA\", \"PaLM\", \"Bard\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"Which company announced the development of a large multimodal model called Gemini in 2022?\",\\n            \"options\": [\"Google\", \"Microsoft\", \"Amazon\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"What is the name of the Google program that aims to develop a world-class multimodal model?\",\\n            \"options\": [\"Gemini\", \"PaLM\", \"Vertex AI\"],\\n            \"answer\": 0\\n        },\\n        {\\n            \"question\": \"In what year did Google start working on ML Fairness?\",\\n            \"options\": [\"2014\", \"2017\", \"2021\"],\\n            \"answer\": 0\\n        }\\n    ]\\n}', 'token_usage': {'prompt_tokens': 1282, 'total_tokens': 1790, 'completion_tokens': 508}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.3-70b-instruct'}, id='run--6e602a09-b205-4d25-8613-9b47c6a5b04c-0', usage_metadata={'input_tokens': 1282, 'output_tokens': 508, 'total_tokens': 1790}, role='assistant')]}\n"
     ]
    }
   ],
   "source": [
    "qcm = qcm_pipeline(\"generative AI\", vectorstore, difficulty=\"medium\", number_of_questions=10, context=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70ec711f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qcm['quiz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc0434cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What type of AI is capable of generating text, images, and code?',\n",
       "  'options': ['Predictive AI', 'Generative AI', 'Multimodal AI'],\n",
       "  'answer': 1},\n",
       " {'question': 'Which of the following is a characteristic of Generative AI?',\n",
       "  'options': ['Limited to predictive analytics',\n",
       "   'Only generates text',\n",
       "   'Can generate text, image, and code'],\n",
       "  'answer': 2},\n",
       " {'question': 'What is the primary function of a Large Language Model (LLM)?',\n",
       "  'options': ['To recognize and interpret human language',\n",
       "   'To predict and generate the next word',\n",
       "   'To analyze and understand visual data'],\n",
       "  'answer': 0},\n",
       " {'question': 'What is an example of a Generative AI application?',\n",
       "  'options': ['Sentiment analysis',\n",
       "   'Image classification',\n",
       "   'Text generation and rewriting'],\n",
       "  'answer': 2},\n",
       " {'question': 'Which company published the Transformer paper in 2017?',\n",
       "  'options': ['Google', 'Facebook', 'Microsoft'],\n",
       "  'answer': 0},\n",
       " {'question': 'What is the name of the chatbot announced by Google in 2023?',\n",
       "  'options': ['LaMDA', 'Bard', 'ChatGPT'],\n",
       "  'answer': 1},\n",
       " {'question': 'What is the primary goal of the Gemini program?',\n",
       "  'options': ['To develop a proprietary language model',\n",
       "   'To create a world-class multimodal model',\n",
       "   'To improve predictive analytics'],\n",
       "  'answer': 1},\n",
       " {'question': 'What type of models are designed to understand, generate, and manipulate human language?',\n",
       "  'options': ['LLMs', 'Language agents', 'Output parsers'],\n",
       "  'answer': 0},\n",
       " {'question': 'In what year did Google start working on ML Fairness?',\n",
       "  'options': ['2014', '2017', '2021'],\n",
       "  'answer': 0},\n",
       " {'question': 'What is the name of the AI model that can store information about past interactions?',\n",
       "  'options': ['Memory agents', 'Language agents', 'Output parsers'],\n",
       "  'answer': 0}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qcm['quiz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cbb077c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a react agent that generate a coding exo question, list of input and expected outputs (to use later for verification)\n",
    "# to check, is the user code correct or not?\n",
    "# generate code (solution) for the exo.\n",
    "# use a tool to run the code with the inputs and verify the outputs to `check if the agent's code or inputs outputs are correct`\n",
    "# stop when the code is correct, and inputs and outputs are valid,\n",
    "# return json format {exo: \"\", solution: \"\", inputs: [], outputs: []}\n",
    "# using langchain Sandbox a code execution environment and react agent to generate coding exercises\n",
    "\n",
    "from langchain_sandbox import PyodideSandboxTool\n",
    "\n",
    "@tool\n",
    "def verify_code(data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Validate user code by running test cases.\n",
    "    Args:\n",
    "        data: A dict with keys 'inputs', 'outputs', 'solution'\n",
    "    Returns:\n",
    "        A dict with keys 'correct' (bool) and 'comment' (str)\n",
    "    \"\"\"\n",
    "    return check_code(data[\"inputs\"], data[\"outputs\"], data[\"solution\"])\n",
    "\n",
    "\n",
    "def coding_exo_pipeline(user_query, vectorstore, difficulty, context):\n",
    "    docs = vectorstore.similarity_search(user_query, k=5)\n",
    "    context_text = \"\\n\".join([d.page_content for d in docs])\n",
    "    context_text=\"\"\n",
    "    llm = ChatNVIDIA(model=MODEL_NAME, nvidia_api_key=os.getenv(\"NVIDIA_API_KEY\"))\n",
    "\n",
    "    sys_msg = SystemMessage(content=(\n",
    "        f\"You are an expert Python coding exercise generator and validator.\\n\\n\"\n",
    "        f\"Context:\\n{context}\\n{context_text}\\n\\n\"\n",
    "        f\"Your task is to:\\n\"\n",
    "        f\"1. Generate a Python coding exercise at the '{difficulty}' level.\\n\"\n",
    "        f\"2. The exercise **must include** the function signature with all parameters and their types, and specify the return type.\\n\"\n",
    "        f\"3. Provide a correct Python solution for the exercise.\\n\"\n",
    "        f\"4. Create at least 3 test cases as a list of inputs (arguments for the function) and the expected output for each input.\\n\"\n",
    "        f\"5. Use the tool `verify_code` to check the correctness of your solution by passing your solution, inputs, and expected outputs.\\n\"\n",
    "        f\"6. If `verify_code` returns incorrect, regenerate the solution and/or test cases and recheck.\\n\"\n",
    "        f\"7. Repeat until the solution passes all test cases and `verify_code` returns correct.\\n\"\n",
    "        f\"8. Ensure a strict 1:1 mapping between inputs and outputs (same length, same order).\\n\"\n",
    "        f\"9. Return only a valid **JSON object** in this format:\\n\"\n",
    "        '''{{\n",
    "        \"exercise\": \"string (clearly state the problem and the exact function signature, including parameter and return types)\",\n",
    "        \"solution\": \"string (Python code)\",\n",
    "        \"inputs\": [[...], [...], ...],  # list of input arguments\n",
    "        \"outputs\": [...]  # expected results (int, str, list, etc.)\n",
    "        }}'''\n",
    "        f\"\\nDO NOT include explanations, markdown, function calls, or code blocks. Only return the raw JSON.\"\n",
    "    ))\n",
    "\n",
    "\n",
    "    human_msg = HumanMessage(content=f\"Generate a coding exercise about: {user_query}\")\n",
    "    tools = [verify_code]\n",
    "    agent = create_react_agent(model=llm, tools=tools, debug=True)\n",
    "    for _ in range(5):\n",
    "        result = agent.invoke({\"messages\": [sys_msg, human_msg]})\n",
    "        try:\n",
    "            content = result['messages'][-1].content.strip().strip(\"```json\").strip(\"```\")\n",
    "            parsed = json.loads(content)\n",
    "            return parsed\n",
    "        except Exception:\n",
    "            raise Exception(\"failed to generate an appropriate json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc4123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instlall deno in your terminal: curl -fsSL https://deno.land/install.sh | sh\n",
    "# export DENO_INSTALL=\"$HOME/.deno\"\n",
    "# export PATH=\"$DENO_INSTALL/bin:$PATH\"\n",
    "# source ~/.bashrc \n",
    "# deno --version\n",
    "# then run this command if it fails. quit you ide or reopen it and execute this cell.\n",
    "# import subprocess\n",
    "# print(subprocess.run([\"deno\", \"--version\"], capture_output=True).stdout.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bae3887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [SystemMessage(content='You are an expert Python coding exercise generator and validator.\\n\\nContext:\\n\\n\\n\\nYour task is to:\\n1. Generate a Python coding exercise at the \\'easy\\' level.\\n2. The exercise **must include** the function signature with all parameters and their types, and specify the return type.\\n3. Provide a correct Python solution for the exercise.\\n4. Create at least 3 test cases as a list of inputs (arguments for the function) and the expected output for each input.\\n5. Use the tool `verify_code` to check the correctness of your solution by passing your solution, inputs, and expected outputs.\\n6. If `verify_code` returns incorrect, regenerate the solution and/or test cases and recheck.\\n7. Repeat until the solution passes all test cases and `verify_code` returns correct.\\n8. Ensure a strict 1:1 mapping between inputs and outputs (same length, same order).\\n9. Return only a valid **JSON object** in this format:\\n{{\\n        \"exercise\": \"string (clearly state the problem and the exact function signature, including parameter and return types)\",\\n        \"solution\": \"string (Python code)\",\\n        \"inputs\": [[...], [...], ...],  # list of input arguments\\n        \"outputs\": [...]  # expected results (int, str, list, etc.)\\n        }}\\nDO NOT include explanations, markdown, function calls, or code blocks. Only return the raw JSON.', additional_kwargs={}, response_metadata={}),\n",
      "              HumanMessage(content='Generate a coding exercise about: function to divide two numbers', additional_kwargs={}, response_metadata={})]}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [SystemMessage(content='You are an expert Python coding exercise generator and validator.\\n\\nContext:\\n\\n\\n\\nYour task is to:\\n1. Generate a Python coding exercise at the \\'easy\\' level.\\n2. The exercise **must include** the function signature with all parameters and their types, and specify the return type.\\n3. Provide a correct Python solution for the exercise.\\n4. Create at least 3 test cases as a list of inputs (arguments for the function) and the expected output for each input.\\n5. Use the tool `verify_code` to check the correctness of your solution by passing your solution, inputs, and expected outputs.\\n6. If `verify_code` returns incorrect, regenerate the solution and/or test cases and recheck.\\n7. Repeat until the solution passes all test cases and `verify_code` returns correct.\\n8. Ensure a strict 1:1 mapping between inputs and outputs (same length, same order).\\n9. Return only a valid **JSON object** in this format:\\n{{\\n        \"exercise\": \"string (clearly state the problem and the exact function signature, including parameter and return types)\",\\n        \"solution\": \"string (Python code)\",\\n        \"inputs\": [[...], [...], ...],  # list of input arguments\\n        \"outputs\": [...]  # expected results (int, str, list, etc.)\\n        }}\\nDO NOT include explanations, markdown, function calls, or code blocks. Only return the raw JSON.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='Generate a coding exercise about: function to divide two numbers', additional_kwargs={}, response_metadata={})]\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [SystemMessage(content='You are an expert Python coding exercise generator and validator.\\n\\nContext:\\n\\n\\n\\nYour task is to:\\n1. Generate a Python coding exercise at the \\'easy\\' level.\\n2. The exercise **must include** the function signature with all parameters and their types, and specify the return type.\\n3. Provide a correct Python solution for the exercise.\\n4. Create at least 3 test cases as a list of inputs (arguments for the function) and the expected output for each input.\\n5. Use the tool `verify_code` to check the correctness of your solution by passing your solution, inputs, and expected outputs.\\n6. If `verify_code` returns incorrect, regenerate the solution and/or test cases and recheck.\\n7. Repeat until the solution passes all test cases and `verify_code` returns correct.\\n8. Ensure a strict 1:1 mapping between inputs and outputs (same length, same order).\\n9. Return only a valid **JSON object** in this format:\\n{{\\n        \"exercise\": \"string (clearly state the problem and the exact function signature, including parameter and return types)\",\\n        \"solution\": \"string (Python code)\",\\n        \"inputs\": [[...], [...], ...],  # list of input arguments\\n        \"outputs\": [...]  # expected results (int, str, list, etc.)\\n        }}\\nDO NOT include explanations, markdown, function calls, or code blocks. Only return the raw JSON.', additional_kwargs={}, response_metadata={}, id='6ddd8d84-3e1a-4e9f-a9fa-01e8d6ed2bed'),\n",
      "              HumanMessage(content='Generate a coding exercise about: function to divide two numbers', additional_kwargs={}, response_metadata={}, id='a14c8ea6-53bb-4956-ba8c-1d71b5969a05')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'is_last_step': False,\n",
      " 'messages': [SystemMessage(content='You are an expert Python coding exercise generator and validator.\\n\\nContext:\\n\\n\\n\\nYour task is to:\\n1. Generate a Python coding exercise at the \\'easy\\' level.\\n2. The exercise **must include** the function signature with all parameters and their types, and specify the return type.\\n3. Provide a correct Python solution for the exercise.\\n4. Create at least 3 test cases as a list of inputs (arguments for the function) and the expected output for each input.\\n5. Use the tool `verify_code` to check the correctness of your solution by passing your solution, inputs, and expected outputs.\\n6. If `verify_code` returns incorrect, regenerate the solution and/or test cases and recheck.\\n7. Repeat until the solution passes all test cases and `verify_code` returns correct.\\n8. Ensure a strict 1:1 mapping between inputs and outputs (same length, same order).\\n9. Return only a valid **JSON object** in this format:\\n{{\\n        \"exercise\": \"string (clearly state the problem and the exact function signature, including parameter and return types)\",\\n        \"solution\": \"string (Python code)\",\\n        \"inputs\": [[...], [...], ...],  # list of input arguments\\n        \"outputs\": [...]  # expected results (int, str, list, etc.)\\n        }}\\nDO NOT include explanations, markdown, function calls, or code blocks. Only return the raw JSON.', additional_kwargs={}, response_metadata={}, id='6ddd8d84-3e1a-4e9f-a9fa-01e8d6ed2bed'),\n",
      "              HumanMessage(content='Generate a coding exercise about: function to divide two numbers', additional_kwargs={}, response_metadata={}, id='a14c8ea6-53bb-4956-ba8c-1d71b5969a05')],\n",
      " 'remaining_steps': 24}\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='{\"exercise\": \"Create a function called divide_numbers that takes two parameters, a and b, both of type float, and returns their division result as a float. The function should handle division by zero and return an error message in this case.\", \"solution\": \"def divide_numbers(a: float, b: float) -> float:\\\\n    if b == 0:\\\\n        return \\\\\"Error: Division by zero\\\\\"\\\\n    return a / b\", \"inputs\": [[10.0, 2.0], [0.0, 5.0], [7.0, 0.0]], \"outputs\": [5.0, 0.0, \"Error: Division by zero\"]}', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': '{\"exercise\": \"Create a function called divide_numbers that takes two parameters, a and b, both of type float, and returns their division result as a float. The function should handle division by zero and return an error message in this case.\", \"solution\": \"def divide_numbers(a: float, b: float) -> float:\\\\n    if b == 0:\\\\n        return \\\\\"Error: Division by zero\\\\\"\\\\n    return a / b\", \"inputs\": [[10.0, 2.0], [0.0, 5.0], [7.0, 0.0]], \"outputs\": [5.0, 0.0, \"Error: Division by zero\"]}', 'token_usage': {'prompt_tokens': 635, 'total_tokens': 781, 'completion_tokens': 146}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.3-70b-instruct'}, id='run--28dc2bda-7823-4e35-9190-b0eac7a9cdec-0', usage_metadata={'input_tokens': 635, 'output_tokens': 146, 'total_tokens': 781}, role='assistant')]\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'messages': [SystemMessage(content='You are an expert Python coding exercise generator and validator.\\n\\nContext:\\n\\n\\n\\nYour task is to:\\n1. Generate a Python coding exercise at the \\'easy\\' level.\\n2. The exercise **must include** the function signature with all parameters and their types, and specify the return type.\\n3. Provide a correct Python solution for the exercise.\\n4. Create at least 3 test cases as a list of inputs (arguments for the function) and the expected output for each input.\\n5. Use the tool `verify_code` to check the correctness of your solution by passing your solution, inputs, and expected outputs.\\n6. If `verify_code` returns incorrect, regenerate the solution and/or test cases and recheck.\\n7. Repeat until the solution passes all test cases and `verify_code` returns correct.\\n8. Ensure a strict 1:1 mapping between inputs and outputs (same length, same order).\\n9. Return only a valid **JSON object** in this format:\\n{{\\n        \"exercise\": \"string (clearly state the problem and the exact function signature, including parameter and return types)\",\\n        \"solution\": \"string (Python code)\",\\n        \"inputs\": [[...], [...], ...],  # list of input arguments\\n        \"outputs\": [...]  # expected results (int, str, list, etc.)\\n        }}\\nDO NOT include explanations, markdown, function calls, or code blocks. Only return the raw JSON.', additional_kwargs={}, response_metadata={}, id='6ddd8d84-3e1a-4e9f-a9fa-01e8d6ed2bed'),\n",
      "              HumanMessage(content='Generate a coding exercise about: function to divide two numbers', additional_kwargs={}, response_metadata={}, id='a14c8ea6-53bb-4956-ba8c-1d71b5969a05'),\n",
      "              AIMessage(content='{\"exercise\": \"Create a function called divide_numbers that takes two parameters, a and b, both of type float, and returns their division result as a float. The function should handle division by zero and return an error message in this case.\", \"solution\": \"def divide_numbers(a: float, b: float) -> float:\\\\n    if b == 0:\\\\n        return \\\\\"Error: Division by zero\\\\\"\\\\n    return a / b\", \"inputs\": [[10.0, 2.0], [0.0, 5.0], [7.0, 0.0]], \"outputs\": [5.0, 0.0, \"Error: Division by zero\"]}', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': '{\"exercise\": \"Create a function called divide_numbers that takes two parameters, a and b, both of type float, and returns their division result as a float. The function should handle division by zero and return an error message in this case.\", \"solution\": \"def divide_numbers(a: float, b: float) -> float:\\\\n    if b == 0:\\\\n        return \\\\\"Error: Division by zero\\\\\"\\\\n    return a / b\", \"inputs\": [[10.0, 2.0], [0.0, 5.0], [7.0, 0.0]], \"outputs\": [5.0, 0.0, \"Error: Division by zero\"]}', 'token_usage': {'prompt_tokens': 635, 'total_tokens': 781, 'completion_tokens': 146}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.3-70b-instruct'}, id='run--28dc2bda-7823-4e35-9190-b0eac7a9cdec-0', usage_metadata={'input_tokens': 635, 'output_tokens': 146, 'total_tokens': 781}, role='assistant')]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exercise': 'Create a function called divide_numbers that takes two parameters, a and b, both of type float, and returns their division result as a float. The function should handle division by zero and return an error message in this case.',\n",
       " 'solution': 'def divide_numbers(a: float, b: float) -> float:\\n    if b == 0:\\n        return \"Error: Division by zero\"\\n    return a / b',\n",
       " 'inputs': [[10.0, 2.0], [0.0, 5.0], [7.0, 0.0]],\n",
       " 'outputs': [5.0, 0.0, 'Error: Division by zero']}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = coding_exo_pipeline(\"function to divide two numbers\", vectorstore, \"easy\", \"\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c920b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6872a956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise: Create a function called divide_numbers that takes two parameters, a and b, both of type float, and returns their division result as a float. The function should handle division by zero and return an error message in this case.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Exercise: {result['exercise']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f115154c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def divide_numbers(a: float, b: float) -> float:\n",
      "    if b == 0:\n",
      "        return \"Error: Division by zero\"\n",
      "    return a / b\n"
     ]
    }
   ],
   "source": [
    "print(result['solution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0d28bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise: [[10.0, 2.0], [0.0, 5.0], [7.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Exercise: {result['inputs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d1ddeb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise: [5.0, 0.0, 'Error: Division by zero']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Exercise: {result['outputs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "718a4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def generate_lab(context: str, number_of_question: int, user_query: str=None, task: str=\"qcm\", difficulty: str=\"easy\", files_paths: List[str]=[]):\n",
    "    if(task not in [\"qcm\", \"code\"]):\n",
    "        raise ValueError(\"Invalid task type. Choose 'qcm' or 'code'.\")\n",
    "    # Load and parse documents\n",
    "    documents = []\n",
    "    for file_path in files_paths:\n",
    "        try:\n",
    "            docs = parse_file(file_path)\n",
    "            documents.extend(docs)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {file_path}: {e}\")\n",
    "    if not documents:\n",
    "        raise ValueError(\"No valid documents found to process.\")\n",
    "    # Chunk the documents\n",
    "    chunked_documents = chunk_documents(documents)\n",
    "    if not chunked_documents:\n",
    "        raise ValueError(\"No valid chunks created from documents.\")\n",
    "    collection_name = files_paths[0].split('/')[-1].split('.')[0] + \"_collection\"\n",
    "    # Index the documents\n",
    "    vectorstore = index_documents(chunked_documents, collection_name=collection_name)\n",
    "    # use the appropriate agent based on the task\n",
    "    if task == \"qcm\":\n",
    "        # results is in a dict\n",
    "        results = qcm_pipeline(user_query, vectorstore, difficulty, context, number_of_question)\n",
    "    else:\n",
    "        results = coding_exo_pipeline(user_query, vectorstore, difficulty, context)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f807dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Any, List\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from langchain_sandbox import PyodideSandboxTool\n",
    "from langchain_nvidia import ChatNVIDIA\n",
    "import re\n",
    "import asyncio\n",
    "\n",
    "\n",
    "def check_code(inputs: list, outputs: list, user_code: str) -> dict:\n",
    "    \"\"\"\n",
    "    Runs user's function against test inputs and outputs using PyodideSandboxTool.\n",
    "    Returns dict with correctness and comment.\n",
    "    \"\"\"\n",
    "\n",
    "    tool = PyodideSandboxTool(allow_net=True)\n",
    "\n",
    "    # Extract function name from user_code\n",
    "    match = re.search(r'def (\\w+)\\s*\\(', user_code)\n",
    "    if not match:\n",
    "        return {\n",
    "            \"correct\": False,\n",
    "            \"comment\": \"### 笶 Problem Identified\\nNo function definition found in user code.\"\n",
    "        }\n",
    "    func_name = match.group(1)\n",
    "\n",
    "    for i, input_args in enumerate(inputs):\n",
    "        try:\n",
    "            # Combine function definition and function call in one execution\n",
    "            call_str = (\n",
    "                f\"{user_code}\\n\"\n",
    "                f\"result = {func_name}(*{input_args})\\n\"\n",
    "                f\"result\"\n",
    "            )\n",
    "            user_output = tool.invoke(call_str)\n",
    "\n",
    "            if user_output != outputs[i]:\n",
    "                return {\n",
    "                    \"correct\": False,\n",
    "                    \"comment\": f\"### 笶 Problem Identified\\nTest case {i} failed: expected {outputs[i]}, got {user_output}\"\n",
    "                }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"correct\": False,\n",
    "                \"comment\": f\"### 笶 Problem Identified\\nError running test case {i}.\\n\\n### 洫 Error:\\n{repr(e)}\"\n",
    "            }\n",
    "\n",
    "    return {\n",
    "        \"correct\": True,\n",
    "        \"comment\": \"### 笨 Solution Analysis\\nAll test cases passed.\"\n",
    "    }\n",
    "def correct_pipeline(exercise: str, user_solution: str, inputs: Any, outputs: Any) -> dict:\n",
    "    llm = ChatNVIDIA(model=MODEL_NAME, nvidia_api_key=os.getenv(\"NVIDIA_API_KEY\"))\n",
    "\n",
    "    sys_msg = SystemMessage(content=(\n",
    "        \"You are a Python expert. Your task is to verify if the user's solution is correct for a given coding exercise.\\n\\n\"\n",
    "        \"Inputs:\\n\"\n",
    "        \"- A coding exercise description\\n\"\n",
    "        \"- A user-provided Python function solution\\n\"\n",
    "        \"- A list of test inputs (list of argument lists)\\n\"\n",
    "        \"- A list of expected outputs\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"1. Use the provided test framework to execute the user's solution.\\n\"\n",
    "        \"If the solution is correct:\\n\"\n",
    "        \"- Return a JSON object:\\n\"\n",
    "        \"{\\n   \\\"correct\\\": true,\\n   \\\"comment\\\": \\\"### 笨 Solution Analysis\\\\nExplain why the solution works correctly.\\\\n\\\\n### 汳｡ Suggestions for Improvement\\\\nMention any ways to make the code better: readability, performance, or Pythonic style.\\\"\\n}\\n\\n\"\n",
    "        \"If the solution is incorrect:\\n\"\n",
    "        \"- Return a JSON object:\\n\"\n",
    "        \"{\\n  \\\"correct\\\": false,\\n   \\\"comment\\\": \\\"### 笶 Problem Identified\\\\nExplain the bug or mistake in the user's solution.\\\\n\\\\n### 洫 Why It Failed\\\\nDescribe clearly why it produces the wrong result.\\\\n\\\\n### 泝ｸ How to Fix or Improve\\\\nGive guidance on how to fix the code and why the fix works.\\\"\\n}\\n\\n\"\n",
    "        \"笞ｸ Only return a valid JSON with exactly two keys: 'correct' and 'comment'.\\n\"\n",
    "        \"笞ｸ Do NOT include any text outside the JSON.\"\n",
    "    ))\n",
    "\n",
    "    human_msg = HumanMessage(content=(\n",
    "        f\"Exercise:\\n{exercise}\\n\\n\"\n",
    "        f\"User solution:\\n{user_solution}\\n\\n\"\n",
    "        f\"Inputs: {inputs}\\n\"\n",
    "        f\"Expected Outputs: {outputs}\"\n",
    "    ))\n",
    "\n",
    "    # Run test locally first using check_code\n",
    "    test_result = check_code(inputs, outputs, user_solution)\n",
    "\n",
    "    return test_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "37f120bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_code(inputs: list, outputs: list, user_code: str) -> dict:\n",
    "    from langchain_sandbox import PyodideSandboxTool\n",
    "    import re\n",
    "\n",
    "    tool = PyodideSandboxTool(allow_net=True)\n",
    "\n",
    "    match = re.search(r'def (\\w+)\\s*\\(', user_code)\n",
    "    if not match:\n",
    "        return {\n",
    "            \"correct\": False,\n",
    "            \"comment\": \"### 笶 Problem Identified\\nNo function definition found in user code.\"\n",
    "        }\n",
    "    func_name = match.group(1)\n",
    "\n",
    "    for i, input_args in enumerate(inputs):\n",
    "        try:\n",
    "            args = input_args if isinstance(input_args, (list, tuple)) else [input_args]\n",
    "            call_str = f\"{user_code}\\nprint({func_name}(*{repr(args)}))\"\n",
    "\n",
    "            user_output = tool.invoke(call_str)\n",
    "            try:\n",
    "                user_output = eval(user_output.strip())\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if user_output != outputs[i]:\n",
    "                return {\n",
    "                    \"correct\": False,\n",
    "                    \"comment\": f\"### 笶 Problem Identified\\nTest case {i} failed: expected {outputs[i]}, got {user_output}\"\n",
    "                }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"correct\": False,\n",
    "                \"comment\": f\"### 笶 Problem Identified\\nError running test case {i}.\\n\\n### 洫 Error:\\n{repr(e)}\"\n",
    "            }\n",
    "\n",
    "    return {\n",
    "        \"correct\": True,\n",
    "        \"comment\": \"### 笨 Solution Analysis\\nAll test cases passed.\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f02cd1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': True, 'comment': '### 笨 Solution Analysis\\nAll test cases passed.'}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = check_code(result['inputs'], result['outputs'], result['solution'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "26fb4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia import ChatNVIDIA\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "MODEL_NAME = \"meta/llama-3.3-70b-instruct\"\n",
    "\n",
    "def evaluate_and_feedback(exercise, solution, inputs, outputs):\n",
    "    # 1. Run check_code\n",
    "    check_result = check_code(inputs, outputs, solution)\n",
    "    correct = check_result[\"correct\"]\n",
    "    comment = check_result[\"comment\"]\n",
    "\n",
    "    # 2. Prepare feedback prompt for the agent\n",
    "    llm = ChatNVIDIA(model=MODEL_NAME, nvidia_api_key=os.getenv(\"NVIDIA_API_KEY\"))\n",
    "    sys_msg = SystemMessage(content=(\n",
    "        \"You are a Python tutor. Given the following exercise, user solution, test results, and feedback, provide constructive feedback to the user.\\n\\n\"\n",
    "        \"Respond in Markdown. If the code is correct, praise the user and suggest improvements. If incorrect, explain the mistake and how to fix it.\"\n",
    "    ))\n",
    "    human_msg = HumanMessage(content=(\n",
    "        f\"Exercise:\\n{exercise}\\n\\n\"\n",
    "        f\"User solution:\\n{solution}\\n\\n\"\n",
    "        f\"Inputs: {inputs}\\n\"\n",
    "        f\"Expected Outputs: {outputs}\\n\"\n",
    "        f\"Test Results: {comment}\\n\"\n",
    "    ))\n",
    "\n",
    "    # 3. Use LangGraph ReAct agent for feedback\n",
    "    agent = create_react_agent(model=llm, tools=[], debug=False)\n",
    "    result = agent.invoke({\"messages\": [sys_msg, human_msg]})\n",
    "    feedback = result['messages'][-1].content\n",
    "\n",
    "    # 4. Return JSON\n",
    "    return {\n",
    "        \"correct\": correct,\n",
    "        \"feedback\": feedback\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3b8f8a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct': True, 'feedback': '### Solution Analysis\\nThe provided solution is correct and meets all the requirements specified in the exercise. Here\\'s why:\\n\\n* The function `divide_numbers` takes two parameters `a` and `b` of type `float`.\\n* It checks if `b` is zero before performing the division.\\n* If `b` is zero, it returns an error message \\'Error: Division by zero\\'.\\n* If `b` is not zero, it returns the division result as a float.\\n\\nHowever, there are a few potential improvements that could be suggested:\\n\\n* Instead of returning a string error message, consider raising a `ZeroDivisionError` exception. This is a more Pythonic way of handling errors and allows the caller to decide how to handle the exception.\\n* Consider adding a docstring to the function to explain what it does, what parameters it takes, and what it returns.\\n* The function could be made more robust by checking if the inputs are actually floats, and raising an error if they are not.\\n\\nHere\\'s an example of how the function could be improved:\\n\\n```python\\ndef divide_numbers(a: float, b: float) -> float:\\n    \"\"\"\\n    Divide two numbers.\\n\\n    Args:\\n        a (float): The dividend.\\n        b (float): The divisor.\\n\\n    Returns:\\n        float: The division result.\\n\\n    Raises:\\n        ZeroDivisionError: If the divisor is zero.\\n        TypeError: If the inputs are not floats.\\n    \"\"\"\\n    if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):\\n        raise TypeError(\"Both inputs must be numbers\")\\n    if b == 0:\\n        raise ZeroDivisionError(\"Cannot divide by zero\")\\n    return a / b\\n```\\n\\nOverall, the original solution is correct, but there are opportunities to make it more robust and Pythonic.'}\n"
     ]
    }
   ],
   "source": [
    "response = evaluate_and_feedback(\n",
    "    exercise=result['exercise'],\n",
    "    solution=result['solution'],\n",
    "    inputs=result['inputs'],\n",
    "    outputs=result['outputs']\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a27f1d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Solution Analysis\n",
       "The provided solution is correct and meets all the requirements specified in the exercise. Here's why:\n",
       "\n",
       "* The function `divide_numbers` takes two parameters `a` and `b` of type `float`.\n",
       "* It checks if `b` is zero before performing the division.\n",
       "* If `b` is zero, it returns an error message 'Error: Division by zero'.\n",
       "* If `b` is not zero, it returns the division result as a float.\n",
       "\n",
       "However, there are a few potential improvements that could be suggested:\n",
       "\n",
       "* Instead of returning a string error message, consider raising a `ZeroDivisionError` exception. This is a more Pythonic way of handling errors and allows the caller to decide how to handle the exception.\n",
       "* Consider adding a docstring to the function to explain what it does, what parameters it takes, and what it returns.\n",
       "* The function could be made more robust by checking if the inputs are actually floats, and raising an error if they are not.\n",
       "\n",
       "Here's an example of how the function could be improved:\n",
       "\n",
       "```python\n",
       "def divide_numbers(a: float, b: float) -> float:\n",
       "    \"\"\"\n",
       "    Divide two numbers.\n",
       "\n",
       "    Args:\n",
       "        a (float): The dividend.\n",
       "        b (float): The divisor.\n",
       "\n",
       "    Returns:\n",
       "        float: The division result.\n",
       "\n",
       "    Raises:\n",
       "        ZeroDivisionError: If the divisor is zero.\n",
       "        TypeError: If the inputs are not floats.\n",
       "    \"\"\"\n",
       "    if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):\n",
       "        raise TypeError(\"Both inputs must be numbers\")\n",
       "    if b == 0:\n",
       "        raise ZeroDivisionError(\"Cannot divide by zero\")\n",
       "    return a / b\n",
       "```\n",
       "\n",
       "Overall, the original solution is correct, but there are opportunities to make it more robust and Pythonic."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display markdown text inside the res['comment']\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(response['feedback']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecef909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {\n",
    "#     'context': Optional[str],\n",
    "#     'user_query': str,\n",
    "#     'type': str,  # 'qcm' or 'code'\n",
    "#     'difficulty': str,  # 'easy', 'medium', 'hard'\n",
    "#     'number_of_questions': int,  # number of questions to generate\n",
    "#     'files_paths': Optional[List[str]],  # paths to files to parse\n",
    "# }\n",
    "\n",
    "# # ila kan task == \"qcm\":\n",
    "# {\n",
    "# \"quiz\": [\n",
    "#     {\n",
    "#     \"question\": \"string\",\n",
    "#     \"options\": [\"option1\", \"option2\", \"option3\"],\n",
    "#     \"answer\": 1\n",
    "#     }\n",
    "# ]\n",
    "# }\n",
    "\n",
    "# # ila kan task == \"code\":\n",
    "# {\n",
    "#     'question': str,  # description of the coding exercise\n",
    "#     'solution': str,  # code solution\n",
    "#     'inputs': List[str],  # list of inputs for the code\n",
    "#     'outputs': List[str]  # expected outputs for the inputs\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e4d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
