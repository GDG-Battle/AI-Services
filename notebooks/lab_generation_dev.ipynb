{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b2537a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "def pptx_parser(file_path):\n",
    "    \"\"\"\n",
    "    Parses a PowerPoint file and returns its content as a list of documents.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the PowerPoint file.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of documents extracted from the PowerPoint file.\n",
    "    \"\"\"\n",
    "    loader = UnstructuredPowerPointLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8eb7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "available_extentions = ['pptx', 'ppt']\n",
    "\n",
    "def parse_file(file_path, extentions=available_extentions):\n",
    "    \"\"\"\n",
    "    Parses a file based on its extension and returns its content.\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    # get the file's extension\n",
    "    file_extension = file_path.split('.')[-1].lower()\n",
    "    if file_extension not in extentions:\n",
    "        raise ValueError(f\"Unsupported file extension: {file_extension}\")\n",
    "    if file_extension in ['pptx', 'ppt']:\n",
    "        return pptx_parser(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file extension: {file_extension}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b44560",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File not found: ../data/Introduction to generative AI.pptx",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m file_path = \u001b[33m\"\u001b[39m\u001b[33m../data/Introduction to generative AI.pptx\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m documents = \u001b[43mparse_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(doc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mparse_file\u001b[39m\u001b[34m(file_path, extentions)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Check if file exists\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(file_path):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# get the file's extension\u001b[39;00m\n\u001b[32m     12\u001b[39m file_extension = file_path.split(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m)[-\u001b[32m1\u001b[39m].lower()\n",
      "\u001b[31mFileNotFoundError\u001b[39m: File not found: ../data/Introduction to generative AI.pptx"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/documents/Introduction to generative AI.pptx\"\n",
    "documents = parse_file(file_path)\n",
    "for doc in documents:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf38a48",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m text_splitter.split_documents(documents)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Chunk the documents\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m chunked_documents = chunk_documents(\u001b[43mdocuments\u001b[49m)\n\u001b[32m     24\u001b[39m chunked_documents\n",
      "\u001b[31mNameError\u001b[39m: name 'documents' is not defined"
     ]
    }
   ],
   "source": [
    "# chunking the documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "def chunk_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Splits documents into smaller chunks.\n",
    "\n",
    "    Args:\n",
    "        documents (list): List of documents to be chunked.\n",
    "        chunk_size (int): Size of each chunk.\n",
    "        chunk_overlap (int): Overlap between chunks.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of text chunks.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "# Chunk the documents\n",
    "chunked_documents = chunk_documents(documents)\n",
    "chunked_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c57c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing the documents using QDrant\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "import os, dotenv\n",
    "from datetime import datetime\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\", \"http://localhost:6333\")\n",
    "EMBEDDING_MODEL_NAME = \"nv-embed-v1\"\n",
    "\n",
    "def index_documents(documents, collection_name=\"pptx_collection\"+str(int(datetime.now().timestamp())), qdrant_url=QDRANT_URL, embedding_model_name=EMBEDDING_MODEL_NAME):\n",
    "    \"\"\"\n",
    "    Indexes documents using QDrant vector store.\n",
    "\n",
    "    Args:\n",
    "        documents (list): List of documents to be indexed.\n",
    "        collection_name (str): Name of the QDrant collection.\n",
    "        qdrant_url (str): URL of the QDrant instance.\n",
    "        embedding_model_name (str): Name of the embedding model to use.\n",
    "\n",
    "    Returns:\n",
    "        Qdrant: The indexed QDrant vector store.\n",
    "    \"\"\"\n",
    "    vectorstore = QdrantVectorStore.from_documents(\n",
    "        documents,\n",
    "        embedding=NVIDIAEmbeddings(model_name=embedding_model_name, nvidia_api_key=os.getenv(\"NVIDIA_API_KEY\")),\n",
    "        collection_name=collection_name,\n",
    "        url=qdrant_url,\n",
    "        prefer_grpc=True,\n",
    "    )\n",
    "    return vectorstore\n",
    "\n",
    "# get vectorstore\n",
    "def get_vectorstore(collection_name=\"pptx_collection\", qdrant_url=QDRANT_URL, embedding_model_name=EMBEDDING_MODEL_NAME):\n",
    "    \"\"\"\n",
    "    get vectorstore with specified collection name and QDrant URL.\n",
    "\n",
    "    Returns:\n",
    "        Qdrant: The QDrant vector store.\n",
    "    \"\"\"\n",
    "    return QdrantVectorStore.from_existing_collection(\n",
    "        collection_name=collection_name,\n",
    "        url=qdrant_url,\n",
    "        embedding=NVIDIAEmbeddings(model_name=embedding_model_name),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e508049",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benhima/pi/ai-services/.venv/lib/python3.12/site-packages/langchain_qdrant/qdrant.py:808: UserWarning: Qdrant client version 1.14.2 is incompatible with server version 1.10.1. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
      "  client = QdrantClient(**client_options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 10 documents into QDrant collection 'genai'.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "vectorstore = index_documents(chunked_documents, collection_name=\"genai\")\n",
    "print(f\"Indexed {len(chunked_documents)} documents into QDrant collection '{vectorstore.collection_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9a6e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benhima/pi/ai-services/.venv/lib/python3.12/site-packages/langchain_qdrant/qdrant.py:397: UserWarning: Qdrant client version 1.14.2 is incompatible with server version 1.10.1. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
      "  client = QdrantClient(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved vectorstore with collection name: genai\n"
     ]
    }
   ],
   "source": [
    "# get the vectorstore\n",
    "vectorstore = get_vectorstore(collection_name=\"genai\")\n",
    "print(f\"Retrieved vectorstore with collection name: {vectorstore.collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ca1b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Multi-Agent Lab Generation Workflow\n",
    "#\n",
    "# Roles:\n",
    "#  - planner_agent: decide QCM vs coding exercise and difficulty level\n",
    "#  - retriever_agent: split documents, embed chunks, retrieve relevant ones\n",
    "#  - qcm_generator_agent: generate MCQ questions/options/correct_answer\n",
    "#  - code_generator_agent: produce coding exercise description and stub\n",
    "#  - test_generator_agent: create unit tests: input/output pairs\n",
    "#  - executor_agent: run the code against tests and capture results\n",
    "#  - evaluator_agent: check test outcomes; if failure, trigger refinement loop\n",
    "#\n",
    "# Workflow:\n",
    "#  1. load_documents(paths: List[str]) -> raw_texts\n",
    "#  2. chunk_texts(raw_texts) -> chunks\n",
    "#  3. embed_and_store(chunks) in vector DB\n",
    "#  4. planner = planner_agent(user_query, metadata)\n",
    "#     if planner.task == \"qcm\":\n",
    "#         chunks = retriever_agent(planner.topic)\n",
    "#         qcms = qcm_generator_agent(chunks, planner.difficulty)\n",
    "#         evaluator_agent.validate_qcm(qcms)\n",
    "#     elif planner.task == \"code\":\n",
    "#         chunks = retriever_agent(planner.topic)\n",
    "#         stub = code_generator_agent(chunks, planner.difficulty)\n",
    "#         tests = test_generator_agent(stub, chunks)\n",
    "#         result = executor_agent.run_tests(stub, tests)\n",
    "#         evaluator_agent.loop_until_pass(stub, tests, result)\n",
    "#\n",
    "# Each agent should be implemented as a separate function or class method.\n",
    "# Use LangChain + LangGraph for orchestration; vector DB for chunk retrieval;\n",
    "# code sandbox for execution.\n",
    "#\n",
    "# Convention:\n",
    "#  - Clear function signatures for each agent\n",
    "#  - Use meaningful names and type hints\n",
    "#  - Keep each agent focused on its responsibility\n",
    "#\n",
    "# Goals:\n",
    "#  - Modular, testable, and easy-to-debug pipeline\n",
    "#  - Support iterative refinement via evaluator loops\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6157c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Workflow steps using LangChain, LangGraph & LangSmith:\n",
    "\n",
    "    1. âœ… Load and preprocess documents\n",
    "       - Use LangChain document loaders (PDF, PPTX, Markdown, code).\n",
    "       - Chunk texts with RecursiveCharacterTextSplitter.\n",
    "       - Embed chunks using OpenAI embeddings.\n",
    "       - Store in vector DB (e.g., FAISS, Qdrant).\n",
    "\n",
    "    2. ðŸ§  Retrieve relevant chunks\n",
    "       - If user_query provided: use retriever to fetch top-k chunks.\n",
    "       - Else: pick default chunks or use metadata filters.\n",
    "\n",
    "    3. ðŸ›  Planner Agent node (LangGraph)\n",
    "       - Decide on task type and difficulty.\n",
    "       - Set up graph path: QCM flow vs Coding exercise flow.\n",
    "\n",
    "    4. ðŸ“‹ QCM Generator node\n",
    "       - Prompt LLM with retrieved chunks + few-shot examples.\n",
    "       - Output: list of questions, options, correct answers.\n",
    "\n",
    "    5. ðŸ’» Code Generator node\n",
    "       - Prompt LLM to generate exercise description & starter code.\n",
    "       - Use few-shot samples of coding exercises and formats.\n",
    "\n",
    "    6. ðŸ§ª Test Generator node\n",
    "       - Prompt LLM to generate unit test cases: inputs & expected outputs.\n",
    "       - Ensure sufficient coverage across edge cases.\n",
    "\n",
    "    7. ðŸš€ Executor node\n",
    "       - Use a safe code execution environment (sandbox).\n",
    "       - Run the code stub against unit test cases, capture results.\n",
    "\n",
    "    8. ðŸ§­ Evaluator node (LangGraph)\n",
    "       - Check if tests passed. If not:\n",
    "           â€¢ Loop back to Code/Test Generator nodes to refine.\n",
    "       - Continue until pass or max retries.\n",
    "\n",
    "    9. âœ… Final output preparation\n",
    "       - Assemble lab payload: QCM items or coding prompt + tests + pass results.\n",
    "       - Return structured JSON or object.\n",
    "\n",
    "    10. âœï¸ LangSmith Integration\n",
    "       - Import tracing via `LANGCHAIN_TRACING_V2=\"true\"` or code decorator.\n",
    "       - Log node-level runs to LangSmith for observability & debugging.\n",
    "       - Optionally use LangSmith Evaluators to auto-score generated labs. :contentReference[oaicite:1]{index=1}\n",
    "\n",
    "    âœ… Use langchain-core + langgraph to build Agent graph and tool connectors :contentReference[oaicite:2]{index=2}\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d496fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from typing import Dict\n",
    "from langchain_qdrant import Qdrant\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "MODEL_NAME = \"meta/llama-3.3-70b-instruct\"\n",
    "\n",
    "# --- QCM generator using ReAct agent ---\n",
    "def qcm_pipeline(user_query: str, vectorstore: Qdrant, difficulty: str) -> Dict:\n",
    "    llm = ChatNVIDIA(model=MODEL_NAME, nvidia_api_key=os.getenv(\"NVIDIA_API_KEY\"))\n",
    "    parser = JsonOutputParser()\n",
    "    llm_with_parser = llm.bind(output_parser=parser)\n",
    "\n",
    "    # Pre-fetch context (5 docs max)\n",
    "    docs = vectorstore.similarity_search(user_query, k=5)\n",
    "    context_text = \"\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    # Prepare prompt with explicit context\n",
    "    sys_msg = SystemMessage(content=(\n",
    "        f\"You are an educational assistant. Using the context below, generate ONE multiple-choice question at '{difficulty}' level. \"\n",
    "        f\"Include exactly 3 plausible options and ONLY ONE correct answer.\\n\"\n",
    "        f\"Context:\\n{context_text}\\n\"\n",
    "        f\"Return JSON only in this format exactly (use double quotes):\\n\"\n",
    "        f'{{\\n'\n",
    "        f'  \"question\": \"string\",\\n'\n",
    "        f'  \"options\": [\"option1\", \"option2\", \"option3\"],\\n'\n",
    "        f'  \"answer\": 0\\n'\n",
    "        f'}}\\n'\n",
    "        f\"Make sure your entire output is a valid JSON object.\"\n",
    "    ))\n",
    "\n",
    "\n",
    "\n",
    "    human_msg = HumanMessage(content=f\"Generate a question about: {user_query}\")\n",
    "\n",
    "    # No retrieval tool needed here, just pass the LLM\n",
    "    agent = create_react_agent(model=llm, tools=[], debug=True)\n",
    "\n",
    "    result = agent.invoke({\"messages\": [sys_msg, human_msg]})\n",
    "\n",
    "    try:\n",
    "        parsed = json.loads(result['messages'][-1].content)\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"Output is not valid JSON:\\n{result['messages'][-1].content}\")\n",
    "\n",
    "    return parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "890af72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [SystemMessage(content='You are an educational assistant. Using the context below, generate ONE multiple-choice question at \\'medium\\' level. Include exactly 3 plausible options and ONLY ONE correct answer.\\nContext:\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\n\\nTransformer-\\x0bbased models published: PaLM, PaLM2, Imagen, Parti, Phenaki\\n\\n2022\\n\\nStable diffusion announced, downloadable\\n\\n2023\\n\\nGoogle Research and \\x0bGoogle DeepMind solidify \\x0blarge model efforts in Gemini \\x0bprogram for a world class \\x0bmultimodal model (Dec)\\n\\n2022\\n\\nGoogle AI Test \\x0bKitchen announces guardrailed LaMDA\\n\\n2017\\n\\nGoogle publishes Transformer paper\\n\\n2018\\n\\nGoogle AI Principles published\\n\\n2022\\n\\nChatGPT \\x0bannounced, available \\x0bto public (Nov)\\n\\n2023\\n\\nBard\\x0bAnnounced \\x0b(Feb)\\n\\n2023\\n\\nDeveloper access, \\x0bCloud access via \\x0bAPI at I/O 2023\\n\\nLarge, pre-Transformer models (e.g., MUM) applied to many products \\x0b(e.g., Google Search, Translate, Maps)\\n\\n\\n\\nTwo important choices\\n\\nProprietary + Confidential\\n\\nWhat Model?\\n\\nWhat Infrastructure?\\n\\nðŸ¤”\\n\\n\\n\\nFinding the right open model\\nReturn JSON only in this format exactly (use double quotes):\\n{\\n  \"question\": \"string\",\\n  \"options\": [\"option1\", \"option2\", \"option3\"],\\n  \"answer\": 0\\n}\\nMake sure your entire output is a valid JSON object.', additional_kwargs={}, response_metadata={}),\n",
      "              HumanMessage(content='Generate a question about: generative AI', additional_kwargs={}, response_metadata={})]}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [SystemMessage(content='You are an educational assistant. Using the context below, generate ONE multiple-choice question at \\'medium\\' level. Include exactly 3 plausible options and ONLY ONE correct answer.\\nContext:\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\n\\nTransformer-\\x0bbased models published: PaLM, PaLM2, Imagen, Parti, Phenaki\\n\\n2022\\n\\nStable diffusion announced, downloadable\\n\\n2023\\n\\nGoogle Research and \\x0bGoogle DeepMind solidify \\x0blarge model efforts in Gemini \\x0bprogram for a world class \\x0bmultimodal model (Dec)\\n\\n2022\\n\\nGoogle AI Test \\x0bKitchen announces guardrailed LaMDA\\n\\n2017\\n\\nGoogle publishes Transformer paper\\n\\n2018\\n\\nGoogle AI Principles published\\n\\n2022\\n\\nChatGPT \\x0bannounced, available \\x0bto public (Nov)\\n\\n2023\\n\\nBard\\x0bAnnounced \\x0b(Feb)\\n\\n2023\\n\\nDeveloper access, \\x0bCloud access via \\x0bAPI at I/O 2023\\n\\nLarge, pre-Transformer models (e.g., MUM) applied to many products \\x0b(e.g., Google Search, Translate, Maps)\\n\\n\\n\\nTwo important choices\\n\\nProprietary + Confidential\\n\\nWhat Model?\\n\\nWhat Infrastructure?\\n\\nðŸ¤”\\n\\n\\n\\nFinding the right open model\\nReturn JSON only in this format exactly (use double quotes):\\n{\\n  \"question\": \"string\",\\n  \"options\": [\"option1\", \"option2\", \"option3\"],\\n  \"answer\": 0\\n}\\nMake sure your entire output is a valid JSON object.', additional_kwargs={}, response_metadata={}),\n",
      " HumanMessage(content='Generate a question about: generative AI', additional_kwargs={}, response_metadata={})]\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [SystemMessage(content='You are an educational assistant. Using the context below, generate ONE multiple-choice question at \\'medium\\' level. Include exactly 3 plausible options and ONLY ONE correct answer.\\nContext:\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\n\\nTransformer-\\x0bbased models published: PaLM, PaLM2, Imagen, Parti, Phenaki\\n\\n2022\\n\\nStable diffusion announced, downloadable\\n\\n2023\\n\\nGoogle Research and \\x0bGoogle DeepMind solidify \\x0blarge model efforts in Gemini \\x0bprogram for a world class \\x0bmultimodal model (Dec)\\n\\n2022\\n\\nGoogle AI Test \\x0bKitchen announces guardrailed LaMDA\\n\\n2017\\n\\nGoogle publishes Transformer paper\\n\\n2018\\n\\nGoogle AI Principles published\\n\\n2022\\n\\nChatGPT \\x0bannounced, available \\x0bto public (Nov)\\n\\n2023\\n\\nBard\\x0bAnnounced \\x0b(Feb)\\n\\n2023\\n\\nDeveloper access, \\x0bCloud access via \\x0bAPI at I/O 2023\\n\\nLarge, pre-Transformer models (e.g., MUM) applied to many products \\x0b(e.g., Google Search, Translate, Maps)\\n\\n\\n\\nTwo important choices\\n\\nProprietary + Confidential\\n\\nWhat Model?\\n\\nWhat Infrastructure?\\n\\nðŸ¤”\\n\\n\\n\\nFinding the right open model\\nReturn JSON only in this format exactly (use double quotes):\\n{\\n  \"question\": \"string\",\\n  \"options\": [\"option1\", \"option2\", \"option3\"],\\n  \"answer\": 0\\n}\\nMake sure your entire output is a valid JSON object.', additional_kwargs={}, response_metadata={}, id='fd933674-49dc-46ed-bd26-a92f4bc69c32'),\n",
      "              HumanMessage(content='Generate a question about: generative AI', additional_kwargs={}, response_metadata={}, id='3a5f3111-d259-4377-9a4e-9e1d2e09aafd')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'is_last_step': False,\n",
      " 'messages': [SystemMessage(content='You are an educational assistant. Using the context below, generate ONE multiple-choice question at \\'medium\\' level. Include exactly 3 plausible options and ONLY ONE correct answer.\\nContext:\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\n\\nTransformer-\\x0bbased models published: PaLM, PaLM2, Imagen, Parti, Phenaki\\n\\n2022\\n\\nStable diffusion announced, downloadable\\n\\n2023\\n\\nGoogle Research and \\x0bGoogle DeepMind solidify \\x0blarge model efforts in Gemini \\x0bprogram for a world class \\x0bmultimodal model (Dec)\\n\\n2022\\n\\nGoogle AI Test \\x0bKitchen announces guardrailed LaMDA\\n\\n2017\\n\\nGoogle publishes Transformer paper\\n\\n2018\\n\\nGoogle AI Principles published\\n\\n2022\\n\\nChatGPT \\x0bannounced, available \\x0bto public (Nov)\\n\\n2023\\n\\nBard\\x0bAnnounced \\x0b(Feb)\\n\\n2023\\n\\nDeveloper access, \\x0bCloud access via \\x0bAPI at I/O 2023\\n\\nLarge, pre-Transformer models (e.g., MUM) applied to many products \\x0b(e.g., Google Search, Translate, Maps)\\n\\n\\n\\nTwo important choices\\n\\nProprietary + Confidential\\n\\nWhat Model?\\n\\nWhat Infrastructure?\\n\\nðŸ¤”\\n\\n\\n\\nFinding the right open model\\nReturn JSON only in this format exactly (use double quotes):\\n{\\n  \"question\": \"string\",\\n  \"options\": [\"option1\", \"option2\", \"option3\"],\\n  \"answer\": 0\\n}\\nMake sure your entire output is a valid JSON object.', additional_kwargs={}, response_metadata={}, id='fd933674-49dc-46ed-bd26-a92f4bc69c32'),\n",
      "              HumanMessage(content='Generate a question about: generative AI', additional_kwargs={}, response_metadata={}, id='3a5f3111-d259-4377-9a4e-9e1d2e09aafd')],\n",
      " 'remaining_steps': 24}\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='{\\n  \"question\": \"What is a primary function of generative AI models?\",\\n  \"options\": [\"To analyze and interpret existing data\", \"To predict outcomes based on historical patterns\", \"To generate new text, images, or code based on learned patterns\"],\\n  \"answer\": 2\\n}', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': '{\\n  \"question\": \"What is a primary function of generative AI models?\",\\n  \"options\": [\"To analyze and interpret existing data\", \"To predict outcomes based on historical patterns\", \"To generate new text, images, or code based on learned patterns\"],\\n  \"answer\": 2\\n}', 'token_usage': {'prompt_tokens': 1229, 'total_tokens': 1290, 'completion_tokens': 61}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.3-70b-instruct'}, id='run--850ce380-d8d8-4305-99ac-bf0a26fe5fe1-0', usage_metadata={'input_tokens': 1229, 'output_tokens': 61, 'total_tokens': 1290}, role='assistant')]\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'messages': [SystemMessage(content='You are an educational assistant. Using the context below, generate ONE multiple-choice question at \\'medium\\' level. Include exactly 3 plausible options and ONLY ONE correct answer.\\nContext:\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nIntroduction to Generative AI\\n\\n\\n\\nKhaoula ALLAK\\n\\nGDG Mentor\\n\\n\\n\\nTable of Contents\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n02\\n\\nFundamentals of Large Language Models \\n\\n03\\n\\nHow to customize the LLM  ? \\n\\n04\\n\\nPractice\\n\\n\\n\\n01\\n\\nWhat is Generative AI ?\\n\\n\\n\\nEvolution of AI \\n\\nWhat matters\\n\\n to us today !\\n\\n\\n\\nEvolution of AI Use Cases\\n\\nPredictive AI\\n\\nGenerative AI\\n\\nMultimodal\\n\\nGenerative AI\\n\\nText, Image & Code Generation\\n\\nText & Code Rewriting & Formatting\\n\\nSummarization\\n\\nExtractive Q&A\\n\\nImage & Video Descriptions\\n\\nRegression & Classification\\n\\nForecasting\\n\\nSentiment Analysis\\n\\nEntity Extraction\\n\\nObject Detection\\n\\nNatural Image Understanding \\n\\nSpatial Reasoning and Logic\\n\\nMathematical Reasoning in Visual Contexts\\n\\nVideo Question Answering\\n\\nAutomatic Speech Recognition & Translation\\n\\n\\n\\n02\\n\\nFundamental of LLMs\\n\\n\\n\\nWhat is LLM? \\n\\nAn LLM is a computer program that has been fed enough examples to able to recognize and interpret human language or other types of complex data.\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nMemory\\n\\nAgents\\n\\nRetaining the entire conversation(store information about past interactions).\\n\\nUse a given language model as a reasoning engine to determine which actions to take .\\n\\nLanguage agents\\n\\nOutput Parsers\\n\\nAre AI models designed to understand, generate, and manipulate human language. They are trained on vast amounts of text data to predict and generate the next word .\\n\\n Interpreting or analyzing the model\\'s output in a structured manner.\\n\\n\\n\\n04\\n\\nLet\\'s practice\\n\\n\\n\\nLearning rag from scratch\\n\\nai.google.dev/\\n\\ngithub.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/\\n\\ncloud.google.com/vertex-ai/docs/generative-ai/tutorials\\n\\nVertex Model Garden\\n\\nHugging Face\\n\\nModel Garden Community Repo\\n\\nExplore Models in Model Garden\\n\\nResources\\n\\n\\n\\n\\n\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\nConversational chatbot architecture \\n\\n\\n\\nTransformational Moments\\n\\n2014\\n\\nGoogle started \\x0bworking on \\x0bML Fairness\\n\\n2017\\n\\nGoogle is \\x0ban AI-first \\x0bcompany\\n\\n2021\\n\\nLaMDA chatbot \\x0bpaper published\\n\\n2022\\n\\nTransformer-\\x0bbased models published: PaLM, PaLM2, Imagen, Parti, Phenaki\\n\\n2022\\n\\nStable diffusion announced, downloadable\\n\\n2023\\n\\nGoogle Research and \\x0bGoogle DeepMind solidify \\x0blarge model efforts in Gemini \\x0bprogram for a world class \\x0bmultimodal model (Dec)\\n\\n2022\\n\\nGoogle AI Test \\x0bKitchen announces guardrailed LaMDA\\n\\n2017\\n\\nGoogle publishes Transformer paper\\n\\n2018\\n\\nGoogle AI Principles published\\n\\n2022\\n\\nChatGPT \\x0bannounced, available \\x0bto public (Nov)\\n\\n2023\\n\\nBard\\x0bAnnounced \\x0b(Feb)\\n\\n2023\\n\\nDeveloper access, \\x0bCloud access via \\x0bAPI at I/O 2023\\n\\nLarge, pre-Transformer models (e.g., MUM) applied to many products \\x0b(e.g., Google Search, Translate, Maps)\\n\\n\\n\\nTwo important choices\\n\\nProprietary + Confidential\\n\\nWhat Model?\\n\\nWhat Infrastructure?\\n\\nðŸ¤”\\n\\n\\n\\nFinding the right open model\\nReturn JSON only in this format exactly (use double quotes):\\n{\\n  \"question\": \"string\",\\n  \"options\": [\"option1\", \"option2\", \"option3\"],\\n  \"answer\": 0\\n}\\nMake sure your entire output is a valid JSON object.', additional_kwargs={}, response_metadata={}, id='fd933674-49dc-46ed-bd26-a92f4bc69c32'),\n",
      "              HumanMessage(content='Generate a question about: generative AI', additional_kwargs={}, response_metadata={}, id='3a5f3111-d259-4377-9a4e-9e1d2e09aafd'),\n",
      "              AIMessage(content='{\\n  \"question\": \"What is a primary function of generative AI models?\",\\n  \"options\": [\"To analyze and interpret existing data\", \"To predict outcomes based on historical patterns\", \"To generate new text, images, or code based on learned patterns\"],\\n  \"answer\": 2\\n}', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': '{\\n  \"question\": \"What is a primary function of generative AI models?\",\\n  \"options\": [\"To analyze and interpret existing data\", \"To predict outcomes based on historical patterns\", \"To generate new text, images, or code based on learned patterns\"],\\n  \"answer\": 2\\n}', 'token_usage': {'prompt_tokens': 1229, 'total_tokens': 1290, 'completion_tokens': 61}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.3-70b-instruct'}, id='run--850ce380-d8d8-4305-99ac-bf0a26fe5fe1-0', usage_metadata={'input_tokens': 1229, 'output_tokens': 61, 'total_tokens': 1290}, role='assistant')]}\n"
     ]
    }
   ],
   "source": [
    "qcm = qcm_pipeline(\"generative AI\", vectorstore, difficulty=\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a430961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(qcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb077c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a react agent that generate a coding exo question, list of input and expected outputs (to use later for verification)\n",
    "# to check, is the user code correct or not?\n",
    "# generate code (solution) for the exo.\n",
    "# use a tool to run the code with the inputs and verify the outputs to `check if the agent's code or inputs outputs are correct`\n",
    "# stop when the code is correct, and inputs and outputs are valid,\n",
    "# return json format {exo: \"\", solution: \"\", inputs: [], outputs: []}\n",
    "\n",
    "def coding_exo_pipeline(user_query, vectorstore, difficulty):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a4457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def generate_lab(user_query: str=None, task: str=\"qcm\", difficulty: str=\"easy\", files_paths: List[str]=[]):\n",
    "    if(task not in [\"qcm\", \"code\"]):\n",
    "        raise ValueError(\"Invalid task type. Choose 'qcm' or 'code'.\")\n",
    "    # Load and parse documents\n",
    "    documents = []\n",
    "    for file_path in files_paths:\n",
    "        try:\n",
    "            docs = parse_file(file_path)\n",
    "            documents.extend(docs)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {file_path}: {e}\")\n",
    "    if not documents:\n",
    "        raise ValueError(\"No valid documents found to process.\")\n",
    "    # Chunk the documents\n",
    "    chunked_documents = chunk_documents(documents)\n",
    "    if not chunked_documents:\n",
    "        raise ValueError(\"No valid chunks created from documents.\")\n",
    "    collection_name = files_paths[0].split('/')[-1].split('.')[0] + \"_collection\"\n",
    "    # Index the documents\n",
    "    vectorstore = index_documents(chunked_documents, collection_name=collection_name)\n",
    "    # use the appropriate agent based on the task\n",
    "    if task == \"qcm\":\n",
    "        # results is in a dict\n",
    "        results = qcm_pipeline(user_query, vectorstore, difficulty)\n",
    "    else:\n",
    "        results = coding_exo_pipeline(user_query, vectorstore, difficulty)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecef909",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
